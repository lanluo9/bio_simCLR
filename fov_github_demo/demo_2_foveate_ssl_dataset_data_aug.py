# -*- coding: utf-8 -*-
"""Demo 2. Foveate_SSL_Dataset_data_aug.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PAfGWtKI9YzlYOSyhGwIzxiST9Dh7epd

# Visualize Distribution of Views for STL10 dataset

For a self-supervised learning system, it's augmentation / data generation pipeline is crucial.
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload 
# %autoreload 2
from ipywidgets import interact, interactive, fixed, interact_manual
import ipywidgets as widgets
from PIL import Image

"""## Prepare STL10 Dataset and Pre-computed Saliency Maps"""

!pip install gdown

import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
from os.path import join
import matplotlib.pylab as plt
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets, transforms, utils

# it took 2-5 mins to download the STL10 dataset
dataset_dir = "/content/Dataset"
dataset = datasets.STL10("Dataset", split="unlabeled", download=True, transform=transforms.ToTensor(),)

# Commented out IPython magic to ensure Python compatibility.
# download the saliency data hosted at my Google Drive.
# %cd Dataset
!gdown https://drive.google.com/uc?id=1tpBwMG1FsmSloqPDSQ6tfRVTeZ3RR89n # TODO: need access / source

# Commented out IPython magic to ensure Python compatibility.
# run generate_salmaps_dataset.py to get stl10_unlabeled_salmaps_salicon.npy to folder /content/Dataset
# %cd /content/
!git clone https://github.com/Animadversio/FastSal

!pip install kornia

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
!git clone https://github.com/Animadversio/Foveated_Saccade_SimCLR.git
# %cd Foveated_Saccade_SimCLR/
!git checkout dev
!git pull

"""## Visualize augmented dataset"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Foveated_Saccade_SimCLR

dataset_dir = "/content/Dataset"

from data_aug.dataset_w_salmap import Contrastive_STL10_w_salmap
from torchvision.transforms import RandomResizedCrop
from data_aug.saliency_random_cropper import RandomResizedCrop_with_Density, RandomCrop_with_Density
from data_aug.visualize_aug_dataset import visualize_samples, visualize_augmented_dataset, visualize_saliency_maps_w_imgs
from data_aug.dataset_w_salmap import Contrastive_STL10_w_CortMagnif, get_RandomMagnifTfm

idxs = [96659, 54019, 88327, 81148, 98469, 77493, 131, 58202, 66666, 65017]

"""### Control"""

# Commented out IPython magic to ensure Python compatibility.
# run generate_salmaps_dataset.py to generate /content/Dataset/stl10_unlabeled_salmaps_salicon.npy

# %cd /content/Foveated_Saccade_SimCLR/
from data_aug.calc_saliency import process_stl10_fastsal
import sys
fastsal_dir = "/content/FastSal"
sys.path.append(fastsal_dir)

# %mv /content/FastSal/utils.py /content/FastSal/utils_fastsal.py 
# rename utils.py in fastsal to avoid calling utils.py in Foveated_Saccade_SimCLR

# /content/Foveated_Saccade_SimCLR/data_aug/calc_saliency.py
# Line 198   from utils_fastsal import load_weight

# /content/FastSal/models/adaptation_layer.py upload my version (see code changes in Demo 1)
process_stl10_fastsal(fastsal_dir + "/weights/salicon_A.pth")

# Commented out IPython magic to ensure Python compatibility.
# process_stl10_fastsal saved to /scratch1/fs1/crponce/Datasets/stl10_unlabeled_salmaps_salicon.npy
# %mv /scratch1/fs1/crponce/Datasets/stl10_unlabeled_salmaps_salicon.npy /content/Dataset/stl10_unlabeled_salmaps_salicon.npy

train_dataset = Contrastive_STL10_w_salmap(dataset_dir=dataset_dir, 
            disable_crop=False, density_cropper=None, split="unlabeled", 
            salmap_control=False, memmap=True)

rndcropper = RandomResizedCrop(96, )
train_dataset.density_cropper = lambda img, salmap: rndcropper(img)
train_dataset.n_views = 7
_, idxs = visualize_samples(train_dataset, idxs)

"""### Experiment 1: Foveation as Blur (without crop)"""

train_dataset = Contrastive_STL10_w_salmap(dataset_dir=dataset_dir, 
            disable_crop=True, density_cropper=None, split="unlabeled", 
            salmap_control=False, memmap=True)

train_dataset.transform = train_dataset.get_simclr_post_crop_transform(96, blur=True, foveation=True,
                  kerW_coef=0.04, fov_area_rng=[0.05, 0.8], bdr=12)
train_dataset.n_views = 7
_, idxs = visualize_samples(train_dataset, idxs)

"""### Experiment 3: Crop + Saliency Based Saccade """

train_dataset = Contrastive_STL10_w_salmap(dataset_dir=dataset_dir,
            density_cropper=None, split="unlabeled", memmap=True) # use memory mapping to load saliency maps to save memory.

crop_temperature = 1
pad_img = 0 # TODO: what is this? not in RandomResizedCrop_with_Density comments?

cropper = RandomResizedCrop_with_Density(96, \
        temperature=crop_temperature, pad_if_needed=pad_img)
cropper.pad_if_needed = False
cropper.temperature = 0.5
train_dataset.n_views = 7
train_dataset.density_cropper = cropper
_, idxs = visualize_samples(train_dataset, idxs)
# _, idxs = visualize_samples(train_dataset, ) # randomly choosing images

"""### Experiment 2: Cortical Magnification"""

del train_dataset

train_dataset = Contrastive_STL10_w_CortMagnif(dataset_dir=dataset_dir,
    transform=None, split="unlabeled", n_views=2,
    crop=False, magnif=True, sal_sample=False, memmap=True)

train_dataset.magnifier = get_RandomMagnifTfm(grid_generator="radial_quad_isotrop",
              bdr=16, fov=20, K=20, cover_ratio=0.3,
              sal_sample=False, )
train_dataset.n_views = 7
_, idxs = visualize_samples(train_dataset, idxs)

"""### Experiment 4: Cortical Magnification + Saliency Based Saccade"""

train_dataset.magnifier = get_RandomMagnifTfm(grid_generator="radial_quad_isotrop",
              bdr=16, fov=20, K=20, cover_ratio=0.3,
              sal_sample=True, sample_temperature=0.5,)
train_dataset.n_views = 7
_, idxs = visualize_samples(train_dataset, idxs)

